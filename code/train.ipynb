{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "device = 'cpu'\n",
    "from textgcn import TextGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(epoch,adj,features,labels,model,opti,loss_func,length1,length2,length3,file):\n",
    "    training_loss=[]\n",
    "    test_loss=[]\n",
    "    training_accuracy=[]\n",
    "    test_accuracy=[]\n",
    "    macro_av_f1=[]\n",
    "    for i in range(epoch):\n",
    "        print(\"Epoch: \",i+1)\n",
    "        model.train()\n",
    "        opti.zero_grad()\n",
    "        output=model(adj,features).to(device)\n",
    "        output1=output[-(length1+length2+length3):-length2-length3]\n",
    "        loss=loss_func(output1,labels[:-length2])\n",
    "        loss.backward()\n",
    "        opti.step()\n",
    "        print(\"Loss: \",loss.item())\n",
    "        training_loss.append(loss.item())\n",
    "        accuracy(adj,features,labels,model,length1,length2,length3,loss_func,training_accuracy,test_accuracy,test_loss,macro_av_f1)\n",
    "        torch.save(model,file+\"model\"+str(i+1)+\".pt\")\n",
    "\n",
    "        print(\"\\n\")\n",
    "    #Save the graph of training loss and test loss and accuracy and macro average f1 score\n",
    "    plt.plot(training_loss)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss\")\n",
    "    plt.savefig(file+\"training_loss.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(test_loss)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Test Loss\")\n",
    "    plt.savefig(file+\"test_loss.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(training_accuracy)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Training Accuracy\")\n",
    "    plt.savefig(file+\"training_accuracy.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(test_accuracy)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Test Accuracy\")\n",
    "    plt.savefig(file+\"test_accuracy.png\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(macro_av_f1)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Macro Average F1 Score\")\n",
    "    plt.title(\"Macro Average F1 Score\")\n",
    "    plt.savefig(file+\"macro_average_f1.png\")\n",
    "    plt.close()\n",
    "\n",
    "    #Save all these values in a txt file\n",
    "    f=open(file+\"result.txt\",\"w\")\n",
    "    for i in range(epoch):\n",
    "        f.write(\"Epoch: \"+str(i+1)+\"\\n\")\n",
    "        f.write(\"Training Loss: \"+str(training_loss[i])+\"\\n\")\n",
    "        f.write(\"Test Loss: \"+str(test_loss[i])+\"\\n\")\n",
    "        f.write(\"Training Accuracy: \"+str(training_accuracy[i])+\"\\n\")\n",
    "        f.write(\"Test Accuracy: \"+str(test_accuracy[i])+\"\\n\")\n",
    "        f.write(\"Macro Average F1 Score: \"+str(macro_av_f1[i])+\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "    f.close()\n",
    "    \n",
    "def accuracy(adj,features,labels,model,length1,length2,length3,loss_func,training_accuracy,test_accuracy,test_loss,macro_av_f1_arr):\n",
    "    model.eval()\n",
    "    with torch.no_grad():   \n",
    "        output=model(adj,features).to(device)\n",
    "        o1=output[-(length1+length2+length3):-length2-length3]\n",
    "        o2=output[-length2-length3:-length3]\n",
    "        l1=labels[:-length2]\n",
    "        l2=labels[length1:]\n",
    "        loss_test=loss_func(o2,l2)\n",
    "        accu1=torch.sum(torch.argmax(o1,dim=1)==l1).item()/len(l1)\n",
    "        accu2=torch.sum(torch.argmax(o2,dim=1)==l2).item()/len(l2)\n",
    "        #Calculate macro average f1 score\n",
    "        macro_av_f1=0\n",
    "        for i in range(2):\n",
    "            tp=0\n",
    "            fp=0\n",
    "            fn=0\n",
    "            for j in range(len(l2)):\n",
    "                if torch.argmax(o2,dim=1)[j]==i:\n",
    "                    if l2[j]==i:\n",
    "                        tp+=1\n",
    "                    else:\n",
    "                        fp+=1\n",
    "                else:\n",
    "                    if l2[j]==i:\n",
    "                        fn+=1\n",
    "            if tp+fp+fn==0:\n",
    "                macro_av_f1+=0\n",
    "            else:\n",
    "                macro_av_f1+=2*tp/(2*tp+fp+fn)\n",
    "        macro_av_f1/=2\n",
    "        print(\"Accuracy for training: \",accu1)\n",
    "        training_accuracy.append(accu1)\n",
    "        print(\"Accuracy for test: \",accu2)\n",
    "        test_accuracy.append(accu2)\n",
    "        print(\"Loss for test: \",loss_test.item())\n",
    "        test_loss.append(loss_test.item())\n",
    "        print(\"Macro Average F1 Score: \",macro_av_f1)\n",
    "        macro_av_f1_arr.append(macro_av_f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj=torch.load('../adj.pt')\n",
    "labels=torch.load('../labels.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read length.txt\n",
    "with open('../utils/length.txt','r') as f:\n",
    "    length=f.read()\n",
    "    length=length.split()\n",
    "    length1=int(length[0])\n",
    "    length2=int(length[1])\n",
    "    length3=int(length[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "a=64\n",
    "b=16\n",
    "dropout=0.5\n",
    "features=torch.load(\"../features.pt\")\n",
    "name=\"modelfinal/0.01_\"+str(a)+\"_\"+str(b)+\"/\"\n",
    "adj=torch.load('../adj.pt')\n",
    "model=TextGCN(len(adj),a,b,2,dropout).to(device)\n",
    "opti=torch.optim.Adam(model.parameters(),lr=0.01)\n",
    "loss_func=torch.nn.CrossEntropyLoss().to(device)\n",
    "if not os.path.exists(name):\n",
    "    os.makedirs(name)\n",
    "training(250,adj,features,labels,model,opti,loss_func,length1,length2,length3,name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
